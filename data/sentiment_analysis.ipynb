{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOqltqt2sTyWBv32xl/QbV/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avichaychriqui/HeBERT/blob/main/data/sentiment_analysis_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydpDDgHtObR-"
      },
      "source": [
        "# !pip install shap==0.36.0\r\n",
        "# !pip install transformers\r\n",
        "# !pip install datasets"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIDsbPBYNHOf"
      },
      "source": [
        "import shap\r\n",
        "import transformers\r\n",
        "import torch\r\n",
        "import numpy as np\r\n",
        "import scipy as sp\r\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8tGWji9NhDv",
        "outputId": "ae1daf52-2090-4f69-f09c-4c5a76988e04"
      },
      "source": [
        "from datasets import load_dataset\r\n",
        "dataset = load_dataset('text', data_files='text_example.txt', )\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset text (/root/.cache/huggingface/datasets/text/default-dba86d70c11ab66c/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdWEAfR3O4AA",
        "outputId": "c1d6b49a-c668-4b93-88b5-02bba1ab5b27"
      },
      "source": [
        "dataset['train']['text'][::-5]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['מה אוכלים היום?',\n",
              " 'קפה זה טעים',\n",
              " 'אני אוהב את העולם',\n",
              " '\" וואו, מתאים לספר השיאים של גינס. מקסים ומרגש!!!! . לא יודעת מי המתורגמנית. אבל יודעת בוודאות כמה זה חשוב!!!! כל כך חשוב. יש מתורגמנית שכולם מכירים מהחדשות בטלויזיה, אפרת נגר המדהימה שהיא גם דולה... עבודת קודש אמיתית. מזל טוב יקרים. הרבה בריאות ושמחה.\"',\n",
              " ' והרכבת ? זה זמן עוד יותר טוב לרכבת שלא פעילה בכלל.. כל הכבוד זה הזמן אבל350 אלף כלי רכב בתקופת הקורונה????',\n",
              " ' והבס שלך לא עבריין??? 3 תיקי אישומים. ',\n",
              " '\" וביבי יצילנו מידם... הוא ולא שרף. 1. תחילה הסתה וגזענות - איבדתה את הרוב של הכנסת2.עתה נגד הדמוקרטיה - הצלחתה לאחד מולך את כל האופוזציה, כולל מבית3. צעד נוסף באותו כיוון - אשריך !\"']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jlc1kleRxp9"
      },
      "source": [
        "\r\n",
        "from transformers import AutoTokenizer, AutoModel, pipeline\r\n",
        "\r\n",
        "# how to use?\r\n",
        "sentiment_analysis = pipeline(\r\n",
        "    \"sentiment-analysis\",\r\n",
        "    model=\"avichr/heBERT_sentiment_analysis\",\r\n",
        "    tokenizer=\"avichr/heBERT_sentiment_analysis\", \r\n",
        "      return_all_scores = True, \r\n",
        ")\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T88MJxFBR53F",
        "outputId": "2f273d1e-9af1-4698-8b12-c152642d8996"
      },
      "source": [
        "for i in dataset['train']['text'][0:5]:\r\n",
        "  print(i, sentiment_analysis(i), sep='\\n')\r\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2yC3wdRO_k3",
        "outputId": "fea1da5c-2136-4fd7-c627-6203d93b93bf"
      },
      "source": [
        "\r\n",
        "\r\n",
        "# load a BERT sentiment analysis model\r\n",
        "tokenizer = transformers.BertTokenizerFast.from_pretrained(\"avichr/heBERT_sentiment_analysis\")\r\n",
        "model = transformers.BertForSequenceClassification.from_pretrained(\"avichr/heBERT_sentiment_analysis\").cuda()\r\n",
        "\r\n",
        "# define a prediction function\r\n",
        "def f(x):\r\n",
        "    tv = torch.tensor([tokenizer.encode(v, pad_to_max_length=True, max_length=500, truncation=True, padding='longest') for v in x]).cuda()\r\n",
        "    outputs = model(tv)[0].detach().cpu().numpy()\r\n",
        "    scores = (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\r\n",
        "    val = sp.special.logit(scores[:,1]) # use one vs rest logit units\r\n",
        "    return val\r\n",
        "\r\n",
        "# build an explainer using a token masker\r\n",
        "explainer = shap.Explainer(f, tokenizer)\r\n",
        "\r\n",
        "# explain the model's predictions on IMDB reviews\r\n",
        "train_dataset = dataset['train']['text']\r\n",
        "shap_values = explainer(train_dataset)\r\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "explainers.Partition is still in an alpha state, so use with caution...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti31Ki0VPTwu"
      },
      "source": [
        "# shap.initjs()\r\n",
        "\r\n",
        "# shap.plots.text(shap_values)\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}
